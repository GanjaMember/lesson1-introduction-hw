## Отчёт по первому домашнему заданию

### 1.1 Создание тензоров

Условие задания:

```
# Создайте следующие тензоры:
# - Тензор размером 3x4, заполненный случайными числами от 0 до 1
# - Тензор размером 2x3x4, заполненный нулями
# - Тензор размером 5x5, заполненный единицами
# - Тензор размером 4x4 с числами от 0 до 15 (используйте reshape)
```

Выход функции:

```
tensor([[1, 1, 0, 1],
        [1, 0, 0, 1],
        [1, 1, 1, 0]])
tensor([[[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])
tensor([[1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1.]])
tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11],
        [12, 13, 14, 15]])
```

## 1.2 Операции с тензорами

Условие задачи:

```
# Дано: тензор A размером 3x4 и тензор B размером 4x3
# Выполните:
# - Транспонирование тензора A
# - Матричное умножение A и B
# - Поэлементное умножение A и транспонированного B
# - Вычислите сумму всех элементов тензора A
```

Выход функции для входных тензоров:

```
tensor([[1., 2., 3.],
        [1., 2., 3.],
        [1., 2., 3.],
        [1., 2., 3.]])
tensor([[ 4.,  8., 12.],
        [ 8., 16., 24.],
        [12., 24., 36.]])
tensor([[1., 1., 1., 1.],
        [4., 4., 4., 4.],
        [9., 9., 9., 9.]])
tensor(24.)
```

## 1.3 Индексация и срезы

Условие задачи:

```
# Создайте тензор размером 5x5x5
# Извлеките:
# - Первую строку
# - Последний столбец
# - Подматрицу размером 2x2 из центра тензора
# - Все элементы с четными индексами
```

Выход функции:

```
tensor([[ 0,  1,  2,  3,  4],
        [ 5,  6,  7,  8,  9],
        [10, 11, 12, 13, 14],
        [15, 16, 17, 18, 19],
        [20, 21, 22, 23, 24]])
tensor([[ 20,  21,  22,  23,  24],
        [ 45,  46,  47,  48,  49],
        [ 70,  71,  72,  73,  74],
        [ 95,  96,  97,  98,  99],
        [120, 121, 122, 123, 124]])
tensor([[81, 82],
        [86, 87]])
tensor([[[  0,   2,   4],
         [ 10,  12,  14],
         [ 20,  22,  24]],

        [[ 50,  52,  54],
         [ 60,  62,  64],
         [ 70,  72,  74]],

        [[100, 102, 104],
         [110, 112, 114],
         [120, 122, 124]]])
```

## 1.4 Работа с формами

Условия задачи:

```
# Создайте тензор размером 24 элемента
# Преобразуйте его в формы:
# - 2x12
# - 3x8
# - 4x6
# - 2x3x4
# - 2x2x2x3
```

Выход функции:

```
tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],
        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]])
tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],
        [ 8,  9, 10, 11, 12, 13, 14, 15],
        [16, 17, 18, 19, 20, 21, 22, 23]])
tensor([[ 0,  1,  2,  3,  4,  5],
        [ 6,  7,  8,  9, 10, 11],
        [12, 13, 14, 15, 16, 17],
        [18, 19, 20, 21, 22, 23]])
tensor([[[ 0,  1,  2,  3],
         [ 4,  5,  6,  7],
         [ 8,  9, 10, 11]],

        [[12, 13, 14, 15],
         [16, 17, 18, 19],
         [20, 21, 22, 23]]])
tensor([[[[ 0,  1,  2],
          [ 3,  4,  5]],

         [[ 6,  7,  8],
          [ 9, 10, 11]]],


        [[[12, 13, 14],
          [15, 16, 17]],

         [[18, 19, 20],
          [21, 22, 23]]]])
```

## 2.1 Простые вычисления с градиентами

Условие задачи:
```
# Создайте тензоры x, y, z с requires_grad=True
# Вычислите функцию: f(x,y,z) = x^2 + y^2 + z^2 + 2*x*y*z
# Найдите градиенты по всем переменным
# Проверьте результат аналитически
```

Ход решения: для аналитического вычисления градиентов нужно вычислить частные производные функции f(x,y,z) по x, y, z

Выход функции:
```
x.grad = tensor([[ 64.,  92.],
        [124., 160.]])
y.grad = tensor([[ 8., 28.],
        [52., 80.]])
z.grad = tensor([[16., 28.],
        [44., 64.]])
```

## 2.2 Градиент функции потерь

Условие задачи:

```
# Реализуйте функцию MSE (Mean Squared Error):
# MSE = (1/n) * Σ(y_pred - y_true)^2
# где y_pred = w * x + b (линейная функция)
# Найдите градиенты по w и b
```

Ход решения: задаем входную матрицу X[n x m] явным образом, w[m x 1] и b[n x 1] инициализируем случайным образом. Вычисляем градиенты двумя способами: с помощью autograd и аналитическим способом. Чтобы вычислить градиент функции потерь для весов нужно вычислить частную производную лосс-функции по весам, для смещения - частная производная по смещению. Для вычисления я изучил материалы статьи https://explained.ai/matrix-calculus/index.html

Выход функции:

```
w.grad = tensor([[-2.5243],
        [-3.4028],
        [-4.2812]])
b.grad = tensor([[-0.4333],
        [-0.3419],
        [-0.1034]])
dw = tensor([[-2.5243],
        [-3.4028],
        [-4.2812]], grad_fn=<MmBackward0>)
db = tensor([[-0.4333],
        [-0.3419],
        [-0.1034]], grad_fn=<MulBackward0>)
```

## 2.3 Цепное правило

Условия задачи:

```
# Реализуйте составную функцию: f(x) = sin(x^2 + 1)
# Найдите градиент df/dx
# Проверьте результат с помощью torch.autograd.grad
```

Ход решения аналогичен решению задач 2.1 и 2.2

Выходы функции:

```
w.grad = tensor([[-0.8323,  1.1346, -5.0344],
        [-2.2013,  6.4692,  9.1850],
        [13.5095, -8.9993, 17.0942]])
```

## 3.1 Подготовка данных

Условие задачи:

```
# Создайте большие матрицы размеров:
# - 64 x 1024 x 1024
# - 128 x 512 x 512
# - 256 x 256 x 256
# Заполните их случайными числами
```

Код создания матриц большого размера

```
x = torch.randn(200, 200, 200)
y = torch.randn(200, 200, 200)
z = torch.randn(200, 200, 200)
```

## 3.2 Функция измерения времени

Условие задачи:
```
# Создайте функцию для измерения времени выполнения операций
# Используйте torch.cuda.Event() для точного измерения на GPU
# Используйте time.time() для измерения на CPU
```

Функция для измерения времени:
```
def time_operation(
    operation: Callable,
    vec: tuple[torch.TensorType],
    vec_gpu: tuple[torch.TensorType],
    operation_name: str,
) -> None:
    """Функция для замера времени выполения операции"""
    # CPU
    cpu_start = time.perf_counter_ns()
    operation(vec)
    cpu_end = time.perf_counter_ns()

    # GPU
    gpu_start = torch.cuda.Event(enable_timing=True)
    gpu_end = torch.cuda.Event(enable_timing=True)

    gpu_start.record()
    operation(vec_gpu)
    gpu_end.record()

    # Ждёт окончания всех процессов, чтобы завершить работу
    torch.cuda.synchronize()

    # Рассчёт метрик
    cpu_time = (cpu_end - cpu_start) * 1000
    gpu_time = gpu_start.elapsed_time(gpu_end)
    acceleration = cpu_time / gpu_time

    print(
        f"{operation_name}| {cpu_time:.1f}  |   {gpu_time:.1f}   |   {acceleration:.1f}"
    )
```

## 3.3 Сравнение операций

Условие задачи:

```
# Сравните время выполнения следующих операций на CPU и CUDA:
# - Матричное умножение (torch.matmul)
# - Поэлементное сложение
# - Поэлементное умножение
# - Транспонирование
# - Вычисление суммы всех элементов

# Для каждой операции:
# 1. Измерьте время на CPU
# 2. Измерьте время на GPU (если доступен)
# 3. Вычислите ускорение (speedup)
# 4. Выведите результаты в табличном виде
```

Таблица результатов:
```
Операция          | CPU (мс) | GPU (мс) | Ускорение
Матричное умножение | 55.3  |   82.4   |   0.7
Поэлементное сложение | 11.3  |   19.3   |   0.6
Поэлементное умножение | 11.4  |   9.6   |   1.2
Транспонирование | 0.1  |   0.1   |   1.6
Сумма элементов | 1.3  |   12.3   |   0.1
```


## 3.4 Анализ результатов:

 1) При разных запусках наибольшее ускорение на GPU получают матричное умножение и поэлементное умножение. Это самые тяжело вычисляемые операции, а, например, для сравнения операция сложения в разы проще них
 2) Потому что на GPU для параллельного выполнения операция они разбиваются на кернелы, которые имеют фиксированное время выполнения, например, 2 - 50 мс. Если CPU выполняет эти операции быстрее времени кернелов, то операции на CPU выполняться раньше
 3) При увеличении размера производительность на CPU падает, а на GPU возрастает, так как на GPU вычисления идут параллельно
 4) При передаче данных между CPU и GPU выделяется память на видеокарте (VRAM), затем данные копируются из оперативной памяти компьютера (RAM) на VRAM через шину PCIe. Эта операция инициируется специальными функциями и может проходить синхронно или асинхронно, при этом скорость передачи ограничивается пропускной способностью PCIe